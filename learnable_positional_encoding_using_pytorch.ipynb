{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Design a learnable positional encoding method using pytorch"
      ],
      "metadata": {
        "id": "v_9OzZ0BBxCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "j8cDyOlmBtGQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "embedding_dim = 16  # Dimensionality of word embeddings\n",
        "hidden_dim = 32  # Dimensionality of hidden states in RNN\n",
        "num_layers = 2  # Number of layers in the RNN\n",
        "learning_rate = 3e-3  # Learning rate for training\n",
        "num_epochs = 25  # Number of training epochs - To view the initial vs updated positional weights clearly\n",
        "\n",
        "# Define dummy dataset parameters\n",
        "num_samples = 40  # Number of samples in the dataset\n",
        "custom_max_sequence_length = 10  # Maximum length of input sequences\n",
        "custom_vocab_size = 12  # Vocabulary size\n",
        "custom_batch_size = 4  # Batch size for training"
      ],
      "metadata": {
        "id": "9p-YXqzCB2ch"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dummy Train dataset\n",
        "data_sequences=torch.randint(0,custom_vocab_size,(num_samples,custom_max_sequence_length))\n",
        "op_labels=torch.randint(0,2,(num_samples,))\n",
        "\n",
        "# Display dataset shapes and examples\n",
        "print(f'{data_sequences.shape=}')\n",
        "print(f'{op_labels.shape=}')\n",
        "print(f'{data_sequences[0]=}')\n",
        "print(f'{op_labels[1]=}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgLrqwujB2Ym",
        "outputId": "861a9a82-e75f-40c9-e605-f3d646027d54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_sequences.shape=torch.Size([40, 10])\n",
            "op_labels.shape=torch.Size([40])\n",
            "data_sequences[0]=tensor([ 3, 10,  7,  7,  7,  1,  9,  8,  3,  2])\n",
            "op_labels[1]=tensor(1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Positional Encoding Layer\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Positional Encoding Layer:\n",
        "    Adds positional encodings to input sequences to provide positional information to the model.\n",
        "\n",
        "    Args:\n",
        "        embedding_dim (int): Dimensionality of word embeddings.\n",
        "        max_length (int): Maximum length of input sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,embedding_dim,max_length):\n",
        "        super(PositionalEncoding,self).__init__()\n",
        "        \"\"\"\n",
        "        Description:\n",
        "            Calls the constructor of the superclass nn.Module within the PositionalEncoding class.\n",
        "            It initializes the PositionalEncoding class,ensuring that the methods and attributes defined in the superclass are also available to the PositionalEncoding class.\n",
        "        \"\"\"\n",
        "        self.embedding_dim=embedding_dim\n",
        "        self.max_length=max_length\n",
        "        self.positional_encoding=nn.Embedding(max_length,embedding_dim)\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Positional Encoding Layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size,sequence_length,embedding_dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with positional encodings added.\n",
        "        \"\"\"\n",
        "        torch_positions=torch.arange(0,x.size(1)).unsqueeze(0).repeat(x.size(0),1).to(x.device)\n",
        "        pos_embedding=self.positional_encoding(torch_positions)\n",
        "        final_vector=x + pos_embedding\n",
        "        return final_vector\n",
        "\n",
        "# Define Custom Model\n",
        "class CustomModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Custom Model:\n",
        "    Basic neural network model that incorporates positional encoding using the PositionalEncoding layer.\n",
        "    Consists of an embedding layer,a positional encoding layer (learnable),a recurrent layer (GRU),and a fully connected layer.\n",
        "\n",
        "    Args:\n",
        "        embedding_dim (int): Dimensionality of word embeddings.\n",
        "        hidden_dim (int): Dimensionality of hidden states in the recurrent layer.\n",
        "        num_layers (int): Number of layers in the recurrent layer.\n",
        "        vocab_size (int): Size of the vocabulary.\n",
        "        max_length (int): Maximum length of input sequences.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,embedding_dim,hidden_dim,num_layers,vocab_size,max_length):\n",
        "        super(CustomModel,self).__init__()\n",
        "        self.embedding=nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.pos_encoder=PositionalEncoding(embedding_dim,max_length)\n",
        "        self.rnn_lay=nn.GRU(embedding_dim,hidden_dim,num_layers,batch_first=True)\n",
        "        self.fc_lay=nn.Linear(hidden_dim,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Simple Model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (batch_size,sequence_length).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after passing through the model.\n",
        "        \"\"\"\n",
        "        x=self.embedding(x)\n",
        "        x=self.pos_encoder(x)\n",
        "        _,h_n=self.rnn_lay(x)\n",
        "        output=self.fc_lay(h_n[-1])\n",
        "        output=output.squeeze(1)\n",
        "        return output"
      ],
      "metadata": {
        "id": "4EZjEprcB2U5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model,loss function,and optimizer\n",
        "pe_learn_model=CustomModel(embedding_dim,hidden_dim,num_layers,custom_vocab_size,custom_max_sequence_length)\n",
        "criterion=nn.BCEWithLogitsLoss()\n",
        "optimizer=optim.Adam([\n",
        "    {'params': pe_learn_model.embedding.parameters()},\n",
        "    {'params': pe_learn_model.pos_encoder.parameters()},\n",
        "    {'params': pe_learn_model.rnn_lay.parameters()},\n",
        "    {'params': pe_learn_model.fc_lay.parameters()}\n",
        "],lr=learning_rate)"
      ],
      "metadata": {
        "id": "MVaEIrqzB2RS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial Positional Encoding Lookup Table\n",
        "initial_pe_weights=pe_learn_model.pos_encoder.positional_encoding.weight.clone().detach()"
      ],
      "metadata": {
        "id": "F5YrKc0RB2OK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss=0\n",
        "    for i in range(0,num_samples,custom_batch_size):\n",
        "        optimizer.zero_grad()\n",
        "        batch_sequences=data_sequences[i:i+custom_batch_size]\n",
        "        batch_labels=op_labels[i:i+custom_batch_size]\n",
        "        output=pe_learn_model(batch_sequences)\n",
        "        loss=criterion(output,batch_labels.float())\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs},Loss: {total_loss}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfH549kcCRYb",
        "outputId": "2d287cd9-8042-446e-ea9c-814ae08e1eaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25,Loss: 6.894695997238159\n",
            "Epoch 2/25,Loss: 6.640145123004913\n",
            "Epoch 3/25,Loss: 6.480790078639984\n",
            "Epoch 4/25,Loss: 6.219516813755035\n",
            "Epoch 5/25,Loss: 5.715315133333206\n",
            "Epoch 6/25,Loss: 4.88611027598381\n",
            "Epoch 7/25,Loss: 3.6961225271224976\n",
            "Epoch 8/25,Loss: 2.2221962064504623\n",
            "Epoch 9/25,Loss: 1.0123903900384903\n",
            "Epoch 10/25,Loss: 0.8180086947977543\n",
            "Epoch 11/25,Loss: 1.510180700570345\n",
            "Epoch 12/25,Loss: 0.6468502841889858\n",
            "Epoch 13/25,Loss: 0.1635905266739428\n",
            "Epoch 14/25,Loss: 0.14276140881702304\n",
            "Epoch 15/25,Loss: 0.08291427814401686\n",
            "Epoch 16/25,Loss: 0.055168478516861796\n",
            "Epoch 17/25,Loss: 0.044889040873385966\n",
            "Epoch 18/25,Loss: 0.0387532499153167\n",
            "Epoch 19/25,Loss: 0.03406481328420341\n",
            "Epoch 20/25,Loss: 0.030309422523714602\n",
            "Epoch 21/25,Loss: 0.027257984620518982\n",
            "Epoch 22/25,Loss: 0.024734648526646197\n",
            "Epoch 23/25,Loss: 0.022610895335674286\n",
            "Epoch 24/25,Loss: 0.020795524469576776\n",
            "Epoch 25/25,Loss: 0.019224266114179045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated Positional Encoding Lookup Table\n",
        "updated_pe_weights=pe_learn_model.pos_encoder.positional_encoding.weight.clone().detach()\n",
        "\n",
        "# Print initial and updated positional encoding weights\n",
        "print(\"-\" * 50)\n",
        "print(f'{initial_pe_weights.shape=},{updated_pe_weights.shape=}')\n",
        "print(f'{initial_pe_weights[0:2]=}')\n",
        "print(f'{updated_pe_weights[0:2]=}')\n",
        "print(f'Trained ? {not(torch.allclose(initial_pe_weights[0:2],updated_pe_weights[0:2]))}')\n",
        "print(\"-\" * 50)\n",
        "print(\"Initial Positional Encoding Lookup Table:\")\n",
        "print(initial_pe_weights)\n",
        "print(\"=\" * 50)\n",
        "print(\"Updated Positional Encoding Lookup Table:\")\n",
        "print(updated_pe_weights)\n",
        "print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68Bvlgh6CRVk",
        "outputId": "389a9aee-a224-4432-93f6-1f76a31e8e7d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "initial_pe_weights.shape=torch.Size([10, 16]),updated_pe_weights.shape=torch.Size([10, 16])\n",
            "initial_pe_weights[0:2]=tensor([[-0.7854,  1.7261,  0.2249, -0.8070, -1.0902,  0.2987,  0.3929,  1.2629,\n",
            "         -0.0936, -1.0125,  0.7450, -0.5617, -0.3318, -1.7285, -0.6494, -0.3264],\n",
            "        [-0.5707,  1.2371, -0.3900,  1.4904, -0.2800,  0.5145,  0.3783,  1.6577,\n",
            "          1.0607, -0.6229,  2.0561,  0.3582, -1.0336,  0.6204, -0.1082, -1.3793]])\n",
            "updated_pe_weights[0:2]=tensor([[-0.7303,  1.8327,  0.3497, -0.8721, -1.1539,  0.2085,  0.3146,  1.3467,\n",
            "         -0.0717, -1.0628,  0.7773, -0.5866, -0.3985, -1.6503, -0.6222, -0.2936],\n",
            "        [-0.6016,  1.1218, -0.3039,  1.5585, -0.3050,  0.5415,  0.4085,  1.7482,\n",
            "          1.0593, -0.6896,  2.1031,  0.3863, -1.1077,  0.7604, -0.0519, -1.3433]])\n",
            "Trained ? True\n",
            "--------------------------------------------------\n",
            "Initial Positional Encoding Lookup Table:\n",
            "tensor([[-0.7854,  1.7261,  0.2249, -0.8070, -1.0902,  0.2987,  0.3929,  1.2629,\n",
            "         -0.0936, -1.0125,  0.7450, -0.5617, -0.3318, -1.7285, -0.6494, -0.3264],\n",
            "        [-0.5707,  1.2371, -0.3900,  1.4904, -0.2800,  0.5145,  0.3783,  1.6577,\n",
            "          1.0607, -0.6229,  2.0561,  0.3582, -1.0336,  0.6204, -0.1082, -1.3793],\n",
            "        [-0.4353,  0.3223,  0.0615,  1.7860,  1.1295,  0.4111,  0.2763,  0.9412,\n",
            "          0.6089,  0.0497, -0.5437, -0.2202, -0.2110, -1.4497,  0.3808,  0.9315],\n",
            "        [ 0.0180, -0.3935, -1.6934, -0.3027, -0.5622, -0.5859,  0.0572,  1.8791,\n",
            "         -1.4201,  2.0294,  0.8966, -0.2426,  0.2318, -0.4552,  0.3141,  0.3858],\n",
            "        [ 0.2323,  0.0522,  1.0356,  0.0542, -0.5166,  0.3805,  1.2041,  0.0221,\n",
            "         -0.8572,  0.2941,  1.6104,  0.4404,  0.4002, -0.5891, -0.4008, -0.5031],\n",
            "        [-1.5901, -0.2828, -0.8471, -0.3145, -0.9111,  0.3093, -2.4116, -0.5039,\n",
            "          0.3568,  0.8065, -0.7825,  0.4035, -0.3267,  0.8470,  0.2256,  0.0758],\n",
            "        [-0.4066,  1.3962, -0.1992,  1.3204,  1.1495,  0.3373, -1.7372, -1.2699,\n",
            "         -0.0587, -1.4481, -0.8142, -0.7437,  0.3728, -0.5181,  1.3140,  1.4095],\n",
            "        [-0.8363,  1.6535, -0.9501, -0.3683,  1.1843, -1.3888, -0.5015, -0.6718,\n",
            "          0.6274, -1.2151,  0.0273, -0.8899, -0.3518,  0.7266, -0.3061, -0.2577],\n",
            "        [ 0.2732,  0.6800, -1.4670, -0.0809, -0.1577,  0.8156, -1.1087, -0.9259,\n",
            "         -0.9958,  0.2398, -0.4268, -0.4217, -0.9928, -0.7192,  0.7880, -1.1074],\n",
            "        [-0.3835, -1.9706,  1.2040, -1.7944,  0.0134,  0.4883, -0.7888, -0.7196,\n",
            "         -1.7791,  0.5393, -1.3157, -0.2394,  1.5031, -0.6414,  0.0372,  0.9529]])\n",
            "==================================================\n",
            "Updated Positional Encoding Lookup Table:\n",
            "tensor([[-0.7303,  1.8327,  0.3497, -0.8721, -1.1539,  0.2085,  0.3146,  1.3467,\n",
            "         -0.0717, -1.0628,  0.7773, -0.5866, -0.3985, -1.6503, -0.6222, -0.2936],\n",
            "        [-0.6016,  1.1218, -0.3039,  1.5585, -0.3050,  0.5415,  0.4085,  1.7482,\n",
            "          1.0593, -0.6896,  2.1031,  0.3863, -1.1077,  0.7604, -0.0519, -1.3433],\n",
            "        [-0.4180,  0.1303,  0.0480,  1.7954,  1.0918,  0.3825,  0.2850,  0.9673,\n",
            "          0.6570,  0.1614, -0.5855, -0.2655, -0.2109, -1.5107,  0.4183,  0.9465],\n",
            "        [-0.0078, -0.2763, -1.7159, -0.3070, -0.5141, -0.6663, -0.0040,  1.8878,\n",
            "         -1.4982,  2.0083,  0.8982, -0.3619,  0.3151, -0.4251,  0.2634,  0.3717],\n",
            "        [ 0.2852, -0.1368,  1.2301,  0.1808, -0.5395,  0.4612,  1.3002,  0.0927,\n",
            "         -0.7394,  0.2433,  1.7315,  0.4409,  0.4625, -0.5540, -0.4290, -0.3924],\n",
            "        [-1.6972, -0.3213, -0.8948, -0.3226, -0.8966,  0.3090, -2.3362, -0.5218,\n",
            "          0.4801,  0.8555, -0.8190,  0.4530, -0.2892,  0.8281,  0.2758,  0.0463],\n",
            "        [-0.3689,  1.4157, -0.2223,  1.3373,  1.0559,  0.2650, -1.7905, -1.3287,\n",
            "          0.0058, -1.3951, -0.7692, -0.7703,  0.3762, -0.4698,  1.3844,  1.3749],\n",
            "        [-0.7737,  1.6665, -0.9126, -0.4088,  1.0952, -1.4141, -0.5828, -0.6859,\n",
            "          0.6236, -1.2071,  0.0961, -0.8832, -0.4232,  0.7236, -0.4548, -0.3033],\n",
            "        [ 0.3404,  0.6655, -1.4989, -0.0990, -0.1574,  0.7916, -1.1714, -0.9838,\n",
            "         -0.9969,  0.2843, -0.3954, -0.4445, -1.0064, -0.7002,  0.8866, -1.1270],\n",
            "        [-0.3982, -2.0468,  1.3962, -1.7472, -0.0054,  0.5381, -0.7066, -0.6858,\n",
            "         -1.7297,  0.4595, -1.3118, -0.2421,  1.5567, -0.6297, -0.0693,  1.0221]])\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dummy validation dataset\n",
        "validation_sequences = torch.randint(0, custom_vocab_size, (num_samples, custom_max_sequence_length))\n",
        "validation_labels = torch.randint(0, 2, (num_samples,))\n",
        "\n",
        "# Making predictions on the validation dataset\n",
        "with torch.no_grad():\n",
        "    val_output = pe_learn_model(validation_sequences)\n",
        "    val_predictions = torch.round(torch.sigmoid(val_output))\n",
        "\n",
        "# Compare predictions with ground truth labels\n",
        "correct_predictions = (val_predictions == validation_labels).sum().item()\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = correct_predictions / len(validation_labels)\n",
        "\n",
        "print(f\"Accuracy: {round(number=(accuracy*100),ndigits=4)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSadpgTHBh-s",
        "outputId": "065da6f2-5c8c-4f2c-acbe-bdbaca3c6f79"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 62.5%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'{validation_labels = }')\n",
        "print(f'{val_output = }')\n",
        "print(f'{torch.round(torch.sigmoid(val_output)) = }')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzgXkq8uFCHu",
        "outputId": "dc16f085-190f-47fa-e0f9-0debfa81aa8c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation_labels = tensor([0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
            "        0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0])\n",
            "val_output = tensor([ 5.7136, -5.2054, -6.6005, -4.2504, -4.0834,  5.9186,  7.2612,  4.7124,\n",
            "        -5.0508,  7.4155, -7.0193,  4.5231,  5.6834,  1.9681, -4.3108,  6.8783,\n",
            "         7.0421, -3.8888, -6.0755, -5.5331,  4.9317,  6.9413,  7.0512,  4.1541,\n",
            "         7.3541,  5.4579, -6.0865,  7.4797,  6.5507,  0.9967, -2.6785,  6.2085,\n",
            "        -4.7132,  6.3882,  7.5549,  1.3410,  2.3158, -4.1999, -2.8665, -0.5916])\n",
            "torch.round(torch.sigmoid(val_output)) = tensor([1., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0.,\n",
            "        0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1.,\n",
            "        1., 0., 0., 0.])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}